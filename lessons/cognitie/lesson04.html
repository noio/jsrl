<html>
    <head>
        <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.0/jquery.min.js"></script>
        <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/flot/0.8/jquery.flot.min.js"></script>
        <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/flot/0.8/jquery.flot.errorbars.min.js"></script>
        <script type="text/javascript" src="../../js/lib/klass.min.js"></script>

        <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <script type="text/javascript" src="../../js/lib/codemirror.min.js"></script>
        <link type="text/css" href="../../js/lib/codemirror.css" media="all" rel="stylesheet">

        <script type="text/javascript" src="../../js/utils.js"></script>
        <script type="text/javascript" src="../../js/learning.js"></script>
        <script type="text/javascript" src="../../js/gridworld.js"></script>
        <link href="../../js/gridworld.css" media="all" rel="stylesheet" type="text/css">

        <script type="text/javascript" src="../../js/projector.js"></script>
        
        <link href="../../style.css" media="all" rel="stylesheet" type="text/css">

        <title>Cognitie Les 3</title>

    </head>
    <body>
        <h1>Practicum Cognitie</h1>
        <div id='projector-description'>
			<h2>Q learning en \(\gamma\)</h2>
			<p>In de vorige les hebben we gezien dat we in de Q-functie
				een parameter \(gamma\) hebben, die reward "in de toekomst" minder zwaar
				telt dan onmiddelijke reward. In dit practicum gaan we zien waarom deze parameter
				handig is en in welke situaties.</p>
				
			<p>Rechts zie je een aantal nieuwe functionaliteiten, ten eerste kun je nu
				zien hoe de kaart wordt opgebouwd in `World'. De <em>a</em>-tjes staan voor
				`moerassen': hier kan de robot doorheen rijden, maar hij heeft een kans van 1 op
				2 dat hij het niet overleeft en dat de episode ten einde komt en hij een negatieve
				reward van -15 krijgt.</p>
				<p>Verder heb je drie soorten reward-tegels:</p>
				<ul>
					<li><strong>x</strong>: een kleine reward van 10.
					<li><strong>y</strong>: een medium reward van 20.
					<li><strong>z</strong>: een grote reward van 30.
				</ul>
			<p>Ook zie je een nieuwe constante PROB_WORLD_END. Deze constante geeft de kans aan
				dat in een willekeurige stap de wereld vergaat. Als je je reward wilt maximaliseren
				moet je hier rekening mee houden: als je in 10 stappen een hele grote reward kan krijgen,
				maar de kans is groot dat voor die tijd de wereld vergaat, dan wil je misschien
				liever een reward pakken die kleiner is, maar dichterbij ligt,</p>

			<p class="question">Op hoeveel stappen ligt de grote reward en op hoeveel stappen ligt
				de kleine reward?</p>
			<p class="question">Hoe groot is de kans dat je de grote reward bereikt voordat de wereld vergaat,
				 als je de snelste route neemt? En hoe groot is die kans voor de kleine reward?</p>
			<p class="question">Hoe groot is de verwachtte return \(E[r]\) als je rechtsreeks
				naar de grote/kleine reward loopt.</p>
			<p class="question">Naar welke reward moet je lopen om je verwachtte reward te maximaliseren?</p>
				
			<p class="question">Draai de simulatie en kijk wat er gebeurt.
				Naar welke research site rijdt de robot nu meestal? Is dit optimaal?</p>
			<p class="question">Welke parameter kun je aanpassen om het gedrag van de robot
				optimaal te maken? Probeer dit uit.</p>
			<p class="question">Zet de kans dat de wereld vergaat nu op
				0.0. Waar gaat de robot nu naar toe?</p>
			<p class="question">Is dit de optimale keuze?</p>				
			<p class="question">Welke parameter kun je aanpassen 
				om de robot wel de optimale keuze te laten maken? Probeer dit uit.</p>				
		<p class="question">Laat de parameters hetzeflde, maar zet nu STEP_REWARD op -10. 
			Wat betekent dit?</p>
			<p class="question">Hoe verandert het gedrag van de robot nu?</p>
			<p class="question">Wat is het fundamentele verschil tussen het aanpassen
				van de STEP_REWARD en de GAMMA-parameter?</p>
			

        </div>

<script id="projector-script">
/**
 * This will run immediately upon load.
 * Put any variables you want to save into 'my'.
 */

var setup = function(my){
	my.panels = projector.createPanels([1,1,1]);
	my.buttons = projector.createButtons(["Play", "Play All", "Get Data"])
	
	var task_world
	var task_world = [
	"z _ _ _ _ _",
	"_ _ _ _ _ _",
	"_ _ _ _ _ x",
	"_ _ _ s _ _",	
	]
	my.task = new gridworld.GridWorld(task_world)
	my.task.setpanel(my.panels[1])
	my.task.STEP_REWARD = 0;
	
	my.task.render();

	my.task.panel.find('.tile.overlay').on('click', function(el){
		console.log('yo')
		var state = $(el.currentTarget).attr('data-coord');
		var statevals = my.Q.get(state)
      	plotActions(my.panels[2], statevals);
      	console.log(state + " Best action: " + argmax(statevals) + ": " + valmax(statevals));
    });

    my.buttons['Get Data'].on('click', function(){
        showDataTable(my.rewards);
    });
}

var first = function(my){
	my.play = my.playAll = false

	var ALPHA
	var GAMMA
	var EPSILON
	var STEP_REWARD
	var PROB_WORLD_END
	var EPISODES
	var task_world
	
	//:edit {"title": "World"}
	task_world = [
	"z _ _ _ _ _",
	"_ _ _ _ _ _",
	"_ _ _ _ _ x",
	"_ _ _ s _ _",	
	]
	//:end edit
	my.task = new gridworld.GridWorld(task_world)
	my.task.setpanel(my.panels[1])
	my.task.STEP_REWARD = 0;
	my.autoplay = false
	my.task.render();

	//:edit {"title":"Variables"}
	ALPHA = 0.49
	GAMMA = 0.99
	EPSILON = 1.0
	PROB_WORLD_END = 0.25
	EPISODES = 1000
	STEP_REWARD = 0
	//:end edit
	my.task.STEP_REWARD = STEP_REWARD

	my.ALPHA = ALPHA
	my.GAMMA = GAMMA
	my.EPISODES = EPISODES
	
	my.task.END_PROBABILITY = PROB_WORLD_END;

	my.Q = new StateActionValueTable()
	var Q = my.Q
	var task = my.task

	//:edit {"title":"Initialization"}
	Q.fill(task.states(), task.actions(), 10.0)
	//:end edit

	// Other persistent variables
	my.steps = []
	my.rewards = []
	my.mean_rewards = []
	my.episode = 0
	my.step = 0;
	my.total_reward = 0;

	// Define functions

	my.action_select = function(s){
		var a
		var As = Q.get(s)

		//:edit {"title":"Action Selection"}
		if (chance(EPSILON))
			a = randompick(As);
		else
			a = argmax(As);
		//:end edit
		return a

	}

	my.update = function(s, a, r, s_){
		var difference
		var new_Q
		GAMMA = my.GAMMA
		//:edit {"title":"Update"}
		delta = r + GAMMA * valmax(Q.get(s_)) - Q.get(s, a)
		new_Q = Q.get(s, a) + ALPHA * delta
		Q.set(s, a, new_Q)
		EPSILON = 0.9999 * EPSILON
		//:end
	}

	my.start_episode = function(){
		task.reset();
		my.step = 0;
		my.episode_reward = 0;
	}

	my.run_episode = function(){
		my.start_episode();
		while(!task.ended()){
			my.do_step();
		}
		my.start_episode()
	}

	my.do_step = function(){
		var s = task.getState();

		var a = my.action_select(s)
		
		if(Math.random() < my.PROB_WORLD_END)
		{
			my.task.finished = true;
			console.log("APOCALYPSE");
		}

		var r = task.act(a);
		
		my.episode_reward += r
		
		var s_ = task.getState();
		
		
		my.update(s, a, r, s_);
		my.step ++;
		



		if (task.ended()){
			console.log("Episode finished in " + my.step + " steps with " + my.episode_reward +" reward .");

			my.steps.push([my.episode, my.step]);
				
			my.total_reward += my.episode_reward;
			
			my.episode ++;
			my.mean_rewards.push([my.episode, my.total_reward / my.episode])
			my.rewards.push([my.episode, my.episode_reward]);

			$.plot(my.panels[0], [{'data':my.rewards,'label':'Return', color:'red'},
								  {'data':my.mean_rewards,'label':'Mean return', color:'orange'}]);
		}
	}
}



var run = function(my, run_num){

	var show_every = 20

	if(my.episode % show_every == 0 && my.episode > 0 && !my.playAll)
	{
		if (my.buttons['Play'].attr('data-justclicked') == 'true') {
			my.play = true;
			my.buttons['Play'].addClass('disabled');
		}

		if (my.buttons['Play All'].attr('data-justclicked') == 'true') {
			my.playAll = my.play = true;			
			my.buttons['Play'].addClass('disabled');
			my.buttons['Play All'].addClass('disabled');
		}

		if (my.play && run_num % 5 == 0) {
			my.do_step();
			my.task.render(my.Q);
		}

	} else {
		my.buttons['Play'].removeClass('disabled');
		my.play = my.playAll;
		my.run_episode();
		my.task.render(my.Q);
	}

	if (my.episode >= my.EPISODES){
		return true;
	}
}
</script>

<script>
    prj = new projector.Projector($('body'));
</script>

</body>
</html>